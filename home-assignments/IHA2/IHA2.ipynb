{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1420bd2a80dfa7d5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# IHA2 - Catching Pokemon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c0cb4dde48293818",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "![](http://tibetanitech.com/wp-content/uploads/2016/09/Pokemon-GO.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b16d667dd74a9079",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "In this home assignment, you'll apply roughly the same principles we used when doing logistic regression on the Iris dataset in Computer Lab 1, but on a new and very interesting dataset. We'll use the [Predict'em All dataset from Kaggle](https://www.kaggle.com/semioniy/predictemall). You can download the dataset from Kaggle but you will need a Kaggle account. This dataset consists of roughly 293,000 [pokemon](http://www.pokemongo.com/) sightings (historical appearances of Pokemon in the Pokemon Go game), with geographical coordinates, time, weather, population density, distance to pokestops/gyms etc. as features. A comprehensive list of all the features is available at [the dataset's homepage](https://www.kaggle.com/semioniy/predictemall)\n",
    "\n",
    "The context is simple: you are a Pokemon hunter, and there are only three Pokemon left for you to complete your collection. You'll do anything to capture them, including changing where you'll spend your next holidays! You know that some Pokemon only spawn in certain places of the world. Since you like machine learning so much, you figure it would be a great idea to train a classifier that, based on a location's latitude and longitude, can tell us which Pokemon is more likely to appear there.\n",
    "\n",
    "The assignment is broken down into six steps.\n",
    "\n",
    "1. Loading the data and extracting the desired subset of it\n",
    "2. Visualization of the dataset\n",
    "3. Preprocessing\n",
    "4. Training\n",
    "5. Evaluation\n",
    "6. Exploration\n",
    "\n",
    "\n",
    "Feel free to add cells wherever you see fit, and play around with this notebook as much as you want when developing the solutions. However, the solution you upload to Canvas must have the exact format shown here, with only the cells present here.\n",
    "\n",
    "Don't restrict yourself only to what was taught so far. Some of the tasks might require you to search for new information. However, **be sure that you do the assignment using PyTorch** since we will be using it through the following assignments as well. [The python docs](https://docs.python.org/3/), [pytorch docs](https://pytorch.org/docs/stable/index.html), [stackoverflow](https://stackoverflow.com/), and Google are your friends!\n",
    "\n",
    "**Hint:** Solving Computer Lab 1 (CL1) is a good way to get prepared for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b9e4c4aa45490941",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-548d168c5c9e8c39",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Import any necessary modules here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4e61b7fa879ef4a1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-50c33a3517aea662",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 1. Loading and extracting subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-32f6c44c22e84d42",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The first step consists of filtering the dataset by the three pokemon you are interested at. \n",
    "\n",
    "Start by loading the `'300k.csv'` file using pandas. If you haven't downloaded it yet, use [this link](https://www.kaggle.com/semioniy/predictemall) to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-53b2a6c0754fca1d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "df = pd.read_csv('300k.csv', low_memory=False)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5d36e8f9780ea946",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Create a new `DataFrame` with only the columns `latitude`, `longitude`, and `class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-318e20fd02ab7f30",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "df = df[['latitude', 'longitude', 'class']]\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6f7970ff67af4649",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Note that the `class` column specifies which pokemon it is. However, it only has the numerical id of the pokemon. For convenience, use the following dictionary to convert between ids and names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-50ff16afeaf933cf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "name_dict={1: 'Bulbasaur', 2: 'Ivysaur', 3: 'Venusaur', 4: 'Charmander', 5: 'Charmeleon', 6: 'Charizard', 7: 'Squirtle', 8: \n",
    "          'Wartortle', 9: 'Blastoise', 10: 'Caterpie', 11: 'Metapod', 12: 'Butterfree', 13: 'Weedle', 14: 'Kakuna', \n",
    "          15: 'Beedrill', 16: 'Pidgey', 17: 'Pidgeotto', 18: 'Pidgeot', 19: 'Rattata', 20: 'Raticate', 21: 'Spearow',\n",
    "          22: 'Fearow', 23: 'Ekans', 24: 'Arbok', 25: 'Pikachu', 26: 'Raichu', 27: 'Sandshrew', 28: 'Sandslash', \n",
    "          29: 'Nidoran F', 30: 'Nidorina', 31: 'Nidoqueen',32: 'Nidoran M', 33: 'Nidorino', 34: 'Nidoking', 35: 'Clefairy',\n",
    "          36: 'Clefable', 37: 'Vulpix', 38: 'Ninetales', 39: 'Jigglypuff', 40: 'Wigglytuff', 41: 'Zubat', 42: 'Golbat', \n",
    "          43: 'Oddish', 44: 'Gloom', 45: 'Vileplume', 46: 'Paras', 47: 'Parasect', 48: 'Venonat', 49: 'Venomoth',\n",
    "          50: 'Diglett', 51: 'Dugtrio', 52: 'Meowth', 53: 'Persian', 54: 'Psyduck',55: 'Golduck', 56: 'Mankey', \n",
    "          57: 'Primeape', 58: 'Growlithe', 59: 'Arcanine', 60: 'Poliwag', 61: 'Poliwhirl', 62: 'Poliwrath',\n",
    "          63: 'Abra', 64: 'Kadabra', 65: 'Alakazam', 66: 'Machop', 67: 'Machoke', 68: 'Machamp', 69: 'Bellsprout', \n",
    "          70: 'Weepinbell', 71: 'Victreebel', 72: 'Tentacool', 73: 'Tentacruel', 74: 'Geodude', 75: 'Graveler',\n",
    "          76: 'Golem', 77: 'Ponyta', 78: 'Rapidash', 79: 'Slowpoke', 80: 'Slowbro', 81: 'Magnemite', 82: 'Magneton',\n",
    "          83: \"Farfetch'd\", 84: 'Doduo', 85: 'Dodrio', 86: 'Seel', 87: 'Dewgong', 88: 'Grimer', 89: 'Muk', \n",
    "          90: 'Shellder', 91: 'Cloyster', 92: 'Gastly', 93: 'Haunter', 94: 'Gengar', 95: 'Onix', 96: 'Drowzee',\n",
    "          97: 'Hypno', 98: 'Krabby', 99: 'Kingler', 100: 'Voltorb', 101: 'Electrode', 102: 'Exeggcute', 103: 'Exeggutor', \n",
    "          104: 'Cubone', 105: 'Marowak', 106: 'Hitmonlee', 107: 'Hitmonchan', 108: 'Lickitung', 109: 'Koffing',\n",
    "          110: 'Weezing', 111: 'Rhyhorn', 112: 'Rhydon', 113: 'Chansey', 114: 'Tangela', 115: 'Kangaskhan', 116: 'Horsea', \n",
    "          117: 'Seadra', 118: 'Goldeen', 119: 'Seaking', 120: 'Staryu', 121: 'Starmie', 122: 'Mr. Mime', 123: 'Scyther', \n",
    "          124: 'Jynx', 125: 'Electabuzz', 126: 'Magmar', 127: 'Pinsir', 128: 'Tauros', 129: 'Magikarp', 130: 'Gyarados', \n",
    "          131: 'Lapras', 132: 'Ditto', 133: 'Eevee', 134: 'Vaporeon', 135: 'Jolteon', 136: 'Flareon', 137: 'Porygon', \n",
    "          138: 'Omanyte', 139: 'Omastar', 140: 'Kabuto', 141: 'Kabutops', 142: 'Aerodactyl', 143: 'Snorlax', 144: 'Articuno',\n",
    "          145: 'Zapdos', 146: 'Moltres', 147: 'Dratini', 148: 'Dragonair', 149: 'Dragonite', 150: 'Mewtwo', 'Bulbasaur': 1, 'Ivysaur': 2, 'Venusaur': 3, 'Charmander': 4, 'Charmeleon': 5, 'Charizard': 6, 'Squirtle': 7, 'Wartortle': 8, 'Blastoise': 9, 'Caterpie': 10, 'Metapod': 11, 'Butterfree': 12, 'Weedle': 13, 'Kakuna': 14, 'Beedrill': 15, 'Pidgey': 16, 'Pidgeotto': 17, 'Pidgeot': 18, 'Rattata': 19, 'Raticate': 20, 'Spearow': 21, 'Fearow': 22, 'Ekans': 23, 'Arbok': 24, 'Pikachu': 25, 'Raichu': 26, 'Sandshrew': 27, 'Sandslash': 28, 'Nidoran F': 29, 'Nidorina': 30, 'Nidoqueen': 31, 'Nidoran M': 32, 'Nidorino': 33, 'Nidoking': 34, 'Clefairy': 35, 'Clefable': 36, 'Vulpix': 37, 'Ninetales': 38, 'Jigglypuff': 39, 'Wigglytuff': 40, 'Zubat': 41, 'Golbat': 42, 'Oddish': 43, 'Gloom': 44, 'Vileplume': 45, 'Paras': 46, 'Parasect': 47, 'Venonat': 48, 'Venomoth': 49, 'Diglett': 50, 'Dugtrio': 51, 'Meowth': 52, 'Persian': 53, 'Psyduck': 54, 'Golduck': 55, 'Mankey': 56, 'Primeape': 57, 'Growlithe': 58, 'Arcanine': 59, 'Poliwag': 60, 'Poliwhirl': 61, 'Poliwrath': 62, 'Abra': 63, 'Kadabra': 64, 'Alakazam': 65, 'Machop': 66, 'Machoke': 67, 'Machamp': 68, 'Bellsprout': 69, 'Weepinbell': 70, 'Victreebel': 71, 'Tentacool': 72, 'Tentacruel': 73, 'Geodude': 74, 'Graveler': 75, 'Golem': 76, 'Ponyta': 77, 'Rapidash': 78, 'Slowpoke': 79, 'Slowbro': 80, 'Magnemite': 81, 'Magneton': 82, 'Farfetch\\'d': 83, 'Doduo': 84, 'Dodrio': 85, 'Seel': 86, 'Dewgong': 87, 'Grimer': 88, 'Muk': 89, 'Shellder': 90, 'Cloyster': 91, 'Gastly': 92, 'Haunter': 93, 'Gengar': 94, 'Onix': 95, 'Drowzee': 96, 'Hypno': 97, 'Krabby': 98, 'Kingler': 99, 'Voltorb': 100, 'Electrode': 101, 'Exeggcute': 102, 'Exeggutor': 103, 'Cubone': 104, 'Marowak': 105, 'Hitmonlee': 106, 'Hitmonchan': 107, 'Lickitung': 108, 'Koffing': 109, 'Weezing': 110, 'Rhyhorn': 111, 'Rhydon': 112, 'Chansey': 113, 'Tangela': 114, 'Kangaskhan': 115, 'Horsea': 116, 'Seadra': 117, 'Goldeen': 118, 'Seaking': 119, 'Staryu': 120, 'Starmie': 121, 'Mr. Mime': 122, 'Scyther': 123, 'Jynx': 124, 'Electabuzz': 125, 'Magmar': 126, 'Pinsir': 127, 'Tauros': 128, 'Magikarp': 129, 'Gyarados': 130, 'Lapras': 131, 'Ditto': 132, 'Eevee': 133, 'Vaporeon': 134, 'Jolteon': 135, 'Flareon': 136, 'Porygon': 137, 'Omanyte': 138, 'Omastar': 139, 'Kabuto': 140, 'Kabutops': 141, 'Aerodactyl': 142, 'Snorlax': 143, 'Articuno': 144, 'Zapdos': 145, 'Moltres': 146, 'Dratini': 147, 'Dragonair': 148, 'Dragonite': 149, 'Mewtwo': 150}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage (you can index either by name or id)\n",
    "print(name_dict['Gengar'])\n",
    "print(name_dict[94])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eaa874b93b3b727c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We are only interested in three specific pokemon: Diglett, Seel, and Tauros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7e0898a53c5649b0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th> <center>Diglett</center> </th>\n",
    "    <th> <center>Seel</center> </th> \n",
    "    <th> <center>Tauros</center> </th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=https://assets.pokemon.com/assets/cms2/img/pokedex/full/050_f2.png alt=Digglet></td>\n",
    "    <td><img src=https://pokemon.gamepedia.com/media/pokemon.gamepedia.com/thumb/f/f1/Seel.png/200px-Seel.png?version=2c32fbe0af2d0da707e5dbcb40472fbf></td>\n",
    "    <td><img src=https://vignette2.wikia.nocookie.net/pokemon/images/0/01/128Tauros_AG_anime.png/revision/latest?cb=20140924030616></td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d091927bf7d7938f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Filter the dataset to contain only these pokemon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7089f3397cbc1f4a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "pokemon = ['Diglett', 'Seel', 'Tauros']\n",
    "pokemon_id = list(map(name_dict.get, pokemon))\n",
    "filtered_df = df[df['class'].isin(pokemon_id)]\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-01b988bb1bfa1f92",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 2. Visualization of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5c7b8fdcd18575fe",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The second step consists of visualizing the dataset. This will help you understand the distribution of the features and get an idea of how hard the task will be.\n",
    "\n",
    "Plot a histogram of the number of occurrences of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c1a9921488e42992",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "filtered_df.hist(column='class', figsize=[15,6], bins=[50,51,86,87,128, 129]);\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c22d835bdc58fe68",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Is the dataset balanced?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3d060bda26842b5d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-931cbd9e3ec95da5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Plot a scatter plot where the first dimension is latitude, the second is longitude, and each point is a Pokemon. Further, the color of each point should represent which Pokemon it is. Lastly, the marker at each point should be an `'x'`. Make sure to label each axis.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- The `scatter` method from `matplotlib` accepts an argument called `c`.\n",
    "- The `scatter` method also accepts an argument called `marker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1120bd5aa8abeae1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "color_dic = {0:'k', 1:'c', 2:'m'}\n",
    "label = pd.get_dummies(filtered_df['class'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "ax.scatter(filtered_df['longitude'],filtered_df['latitude'], c=list(map(color_dic.get, np.argmax(label.values, axis=1))), marker='x');\n",
    "\n",
    "# Manually add legend entries\n",
    "import matplotlib.patches as mpatches\n",
    "patch1 = mpatches.Patch(color='k', label='Diglett')\n",
    "patch2 = mpatches.Patch(color='c', label='Seel')\n",
    "patch3 = mpatches.Patch(color='m', label='Tauros')\n",
    "ax.legend(handles=[patch1, patch2, patch3]);\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-76f326a05bf22e09",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Is there any other visualization you think would be useful? If so, insert it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-86724bfd3955c5ed",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7af3ac7849dc5252",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "How hard do you think the problem is? Which classes can/cannot be easily separated?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-62e50deb2cca74b2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**Your answer here:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3d322369934aa289",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Which accuracy do you expect to achieve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f2c255ad5dd7e5fc",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**Your answer here:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-451e0813fca28b8b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3eed8190495b60ac",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The third step consists of processing the data before training, such as dividing the dataset into training, validation, and test sets. Some tranformations can also be applied to the dataset in order to improve the performance of the network. \n",
    "\n",
    "Start by creating the input and output vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c61cb8065babf0c5",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "x = filtered_df[['latitude', 'longitude']].values\n",
    "y = pd.get_dummies(filtered_df['class']).values\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-566d2f340fa57d49",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Separate your data into training (55%), validation (25%) and test sets (20%). If you wish to apply any transformation to the dataset, do it here as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-918e3bb4d74472bd",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.3, random_state=0)\n",
    "\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        'Initialization'\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "\n",
    "        # Get data and label\n",
    "        X = self.features[index]\n",
    "        y = self.labels[index]\n",
    "        y = y.argmax()\n",
    "        return X, y\n",
    "\n",
    "dataset_train = Dataset(x_train, y_train)\n",
    "dataset_val = Dataset(x_val, y_val)\n",
    "dataset_test = Dataset(x_test, y_test)\n",
    "\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size)\n",
    "val_loader = DataLoader(dataset_val, batch_size=batch_size)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b9088197f0ab661c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1c4e4c6b7186c418",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The fourth step is where you will choose the architecture of your network (number of hidden layers, activation functions, etc.), and train it. \n",
    "\n",
    "Start by choosing an architecture for your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-dff32f0d1dd91a72",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "N, D_in, H, D_out = 2, 2, 40, 3\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(H,H),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(H,H),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(H,D_out),\n",
    "    torch.nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                                  else \"cpu\")\n",
    "                \n",
    "\n",
    "model.to(device)                      \n",
    "criterion = torch.nn.NLLLoss()\n",
    "model = model.double()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d91e1230c6b9225d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-711ca3d58ad725b4",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "num_epochs = 100\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 10\n",
    "train_losses, test_losses = [], []\n",
    "for epoch in range(num_epochs):\n",
    "    # Train:   \n",
    "    for batch_index, (x, y) in enumerate(train_loader):\n",
    "        steps += 1\n",
    "        inputs, labels = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        z = model.forward(inputs)\n",
    "        loss = criterion(z, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_index, (x, y) in enumerate(val_loader):\n",
    "                    inputs, labels = x.to(device), y.to(device)\n",
    "                    z = model.forward(inputs)\n",
    "                    batch_loss = criterion(z, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    ps = torch.exp(z)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            train_losses.append(running_loss/len(train_loader))\n",
    "            test_losses.append(test_loss/len(val_loader))                    \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(val_loader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(val_loader):.3f}\")\n",
    "            running_loss = 0\n",
    "            #model.train()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-72062a93915888b4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "For you to pass this assignment, you must obtain an accuracy on the validation set greater than 50%. It may be necessary to search for a good architecture by trying several different ones. If you want a challenge, try getting an accuracy greater than 63%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-effc356fff18a4b5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b2bbee2adf94b7d3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Once you achieved at least 50% accuracy in the validation set, we are done with training. Now we'll evaluate the performance of your classifier on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3f4ab762e2890554",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Compute the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-64d1008aafb3e518",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "test_loss = 0\n",
    "accuracy = 0\n",
    "model.eval()\n",
    "for batch_index, (x, y) in enumerate(test_loader):\n",
    "    inputs, labels = x.to(device), y.to(device)\n",
    "    z = model.forward(inputs)\n",
    "    batch_loss = criterion(z, labels)\n",
    "    test_loss += batch_loss.item()\n",
    "\n",
    "    ps = torch.exp(z)\n",
    "    top_p, top_class = ps.topk(1, dim=1)\n",
    "    equals = top_class == labels.view(*top_class.shape)\n",
    "    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()                 \n",
    "print(f\"Test loss: {accuracy/len(test_loader):.3f}.. \")\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8232dd159f8d4887",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Compute the confusion matrix of your predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9475a5163acc3249",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(top_class.cpu(), labels.cpu())\n",
    "#print(top_class.cpu().transpose(0,1))\n",
    "#print(labels.cpu())\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a5e9c635fcf0e14d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "What can you conclude from the computed accuracy and confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b93435335accba07",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**Your answer here:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d64ba10a699f05f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Visualize the decision regions of the network. Overlap it with the points corresponding to the training data, such as in Section 2, by using the scatter plot function.\n",
    "\n",
    "Hint: A simple way to do it is to generate a lot of points within a predefined range of longitude and latitude and apply your network to it. However, feel free to explore other ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2cfbecf57fd1043f",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "max_x = np.max(x_train)*1.1\n",
    "\n",
    "rand_tensor = torch.randn((10000,2), dtype=torch.float64)\n",
    "max2_x = torch.max(rand_tensor)\n",
    "rand_tensor = rand_tensor*max_x/max2_x\n",
    "\n",
    "y_const = torch.ones((10000,1))\n",
    "y_label = np.ones((10000,))\n",
    "\n",
    "dataset_vis = Dataset(rand_tensor, y_const)\n",
    "vis_loader = DataLoader(dataset_vis, batch_size=batch_size)\n",
    "\n",
    "model.eval()\n",
    "for batch_index, (x, y) in enumerate(vis_loader):\n",
    "    inputs, labels = x.to(device), y.to(device)\n",
    "    z = model.forward(inputs)\n",
    "    batch_loss = criterion(z, labels)\n",
    "    test_loss += batch_loss.item()\n",
    "\n",
    "    ps = torch.exp(z)\n",
    "    top_p, top_class = ps.topk(1, dim=1)\n",
    "    idx_min = batch_size*batch_index\n",
    "    idx_max = batch_size*(batch_index+1)\n",
    "    y_label[idx_min:idx_max,] = top_class.cpu()[:,0]\n",
    "\n",
    "color_dic = {0:'tab:orange', 1:'c', 2:'lime'}\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "ax.scatter(rand_tensor[:,1],rand_tensor[:,0], c=list(map(color_dic.get, y_label)), marker='o');\n",
    "\n",
    "color_dic = {0:'r', 1:'b', 2:'g'}\n",
    "ax.scatter(filtered_df['longitude'],filtered_df['latitude'], c=list(map(color_dic.get, np.argmax(label.values, axis=1))), marker='x');\n",
    "\n",
    "\n",
    "# Manually add legend entries\n",
    "import matplotlib.patches as mpatches\n",
    "patch1 = mpatches.Patch(color='tab:orange', label='Diglett')\n",
    "patch2 = mpatches.Patch(color='c', label='Seel')\n",
    "patch3 = mpatches.Patch(color='lime', label='Tauros')\n",
    "patch4 = mpatches.Patch(color='r', label='Diglett')\n",
    "patch5 = mpatches.Patch(color='b', label='Seel')\n",
    "patch6 = mpatches.Patch(color='g', label='Tauros')\n",
    "ax.legend(handles=[patch1, patch2, patch3, patch4, patch5, patch6]);\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2356390d7821c9a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Do the learned decision regions look like you would expect? Please comment on your results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8d948a53e74c0181",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer here:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b731aebed710ae07",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 6. Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-79904bd828487a07",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "You have now trained and evaluated a neural network for this particular classification task. Can you provide a brief explanation as to how you could use it to decide where to travel, if you're interested in capturing the aforementioned Pokemons?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-79ac9ff2b09a41b5",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**Your answer here:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8041a4537430ba53",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Is (are) there any other feature(s) from the original dataset (e.g. hour of the day, pressure, wind speed, population density, etc.) which you think would be valuable to add as an input feature to your classifier to improve its performance? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c2def6009a95f2a6",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**Your answer here:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e9f21e8b0fe33751",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "To investigate your hypothesis, plot a histogram of the selected feature(s) for each one of the pokemons we're interested in. For example, if you think pressure and population density are valuable for prediction, plot 6 histograms. 3 of them will be the pressure histograms for each class ('Diglett', 'Seel' and 'Tauros'), and the other 3 will be the population density for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b18deaa33c46ec92",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f51c8bdfaf2e03f4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "What does(do) this(ese) histogram(s) show you? Could it be beneficial to add this(ese) new feature(s) as input? Explain why/why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f9522e4fa9c010be",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**Your answer here:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-284bf5af1750b1b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The purpose was this assignment was mostly to make you design a network for classification, using this Pokemon dataset as use case. However, if you want to find those three particular Pokemons, most likely using a network for classification is not the best approach. An alternative would be to perform localization by using regression instead. **Can you state some pros and cons of approach this as a regression problem instead of a classification problem?** (We do not except very detailed answers, you will pass the assignment as long as you make a reasonable attempt at explaining the pros and cons.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-bd241242621ae646",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer here:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fccdd48334c7c70c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 7. (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3e8a75d10f4fb404",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Assuming you found useful new features in the last part of this assignment, train a new classifier that uses these featues as well. Did the accuracy on the validation set improve? What's the highest accuracy you can achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c4a9ddfda9cd7a08",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
