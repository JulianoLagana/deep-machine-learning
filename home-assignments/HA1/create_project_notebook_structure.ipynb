{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the project structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates the folder structure necessary for HA1. This should be run from the same folder where the `dogs-vs-cats.zip` file you downloaded from Kaggle is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dealing with files\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# For using regex expressions\n",
    "import re\n",
    "\n",
    "# For splitting the data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NOTE: This script assumes that you have the `dogs-vs-cats.zip` in the same directory as this notebook\n",
    "\n",
    "pre_existing_item = [\"test1.zip\",\n",
    "                     \"test\",\n",
    "                     \"val\",\n",
    "                     \"train.zip\",\n",
    "                     \"train\",\n",
    "                     \"train_all\",\n",
    "                     \"sampleSubmission.csv\",\n",
    "                     \"small_train\",\n",
    "                     \"small_val\"\n",
    "                     ]\n",
    "\n",
    "for item in pre_existing_item:\n",
    "    item = Path(item)\n",
    "    if item.exists():\n",
    "        if item.is_dir():\n",
    "            shutil.rmtree(item)\n",
    "        elif item.is_file():\n",
    "            item.unlink()\n",
    "        else:\n",
    "            print(\"Unknown item: {}, remove manually\".format(item))\n",
    "\n",
    "\n",
    "# Depending on your machine the following might take some seconds to run\n",
    "# `!unzip` runs the unzip command on your system, i.e. you must have unzip installed.\n",
    "# ` The docker environment has `unzip` installed but if you're not using docker\n",
    "# the command might fail and you need to unzip manually.\n",
    "!unzip -q dogs-vs-cats.zip\n",
    "!unzip -q test1.zip\n",
    "!unzip -q train.zip\n",
    "\n",
    "Path(\"test1\").rename(\"test\")\n",
    "Path(\"train\").rename(\"train_all\")\n",
    "\n",
    "\n",
    "# Remove sub zip files\n",
    "Path(\"test1.zip\").unlink()\n",
    "Path(\"train.zip\").unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_path = Path.cwd() / \"train_all\"\n",
    "\n",
    "# Get a list of all filenames inside (these will be used for training and validation)\n",
    "all_cat_filenames = list(train_all_path.glob(\"cat.*.jpg\"))\n",
    "all_dog_filenames = list(train_all_path.glob(\"dog.*.jpg\"))\n",
    "\n",
    "print('Found {} images of cats.\\nFound {} images of dogs.'.format(len(all_cat_filenames),\n",
    "                                                                  len(all_dog_filenames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create the `'small_train'` and `'small_val'` folders for a smaller subset of the original dataset (the assignment asks for 20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a subset of the entire training dataset (20%)\n",
    "_, few_cat_filenames, _, few_dog_filenames = train_test_split(all_cat_filenames, \n",
    "                                                              all_dog_filenames, \n",
    "                                                              test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split it into training and validation sets\n",
    "split_ratio_small_dataset = 0.3\n",
    "\n",
    "few_cat_filenames_train, few_cat_filenames_val, few_dog_filenames_train, few_dog_filenames_val = \\\n",
    "train_test_split(few_cat_filenames, \n",
    "              few_dog_filenames, \n",
    "              test_size = split_ratio_small_dataset,\n",
    "              random_state = 2)\n",
    "\n",
    "print('The smaller dataset will be comprised of:')\n",
    "print('Train:\\t', len(few_cat_filenames_train), 'cats and', len(few_dog_filenames_train), 'dogs.')\n",
    "print('Val:\\t', len(few_cat_filenames_val), 'cats and', len(few_dog_filenames_val), 'dogs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train and val directories and subdirectories\n",
    "subdirectories = {\"small_train/cats\": few_cat_filenames_train,\n",
    "                 \"small_train/dogs\": few_dog_filenames_train,\n",
    "                 \"small_val/cats\": few_cat_filenames_val,\n",
    "                 \"small_val/dogs\": few_dog_filenames_val\n",
    "                 }\n",
    "\n",
    "for subdirectory in subdirectories.keys():\n",
    "    subdirectory = Path(subdirectory)\n",
    "    subdirectory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Put the training and validation data in the respective folders\n",
    "def fill_sub_dir_symlink(sub_dir, file_subset):\n",
    "    \"\"\"This function uses symbolic links\"\"\"\n",
    "    for file in file_subset:\n",
    "        symbolic_path = Path.cwd() / sub_dir / file.name\n",
    "        symbolic_path.symlink_to(file)\n",
    "        \n",
    "for sub_dir, file_subset in subdirectories.items():\n",
    "    fill_sub_dir_symlink(sub_dir, file_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the `'val'` and `'train'` folders for the entire dataset. You need to specify the train/val split (but something reasonable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose\n",
    "split_ratio_big_dataset = 0.3\n",
    "\n",
    "if not split_ratio_big_dataset:\n",
    "    raise ValueError(\"'split_ratio_big_dataset' must have a value between 0 and 1.\")\n",
    "\n",
    "# Split it\n",
    "all_cat_filenames_train, all_cat_filenames_val, all_dog_filenames_train, all_dog_filenames_val = \\\n",
    "train_test_split(all_cat_filenames,\n",
    "                 all_dog_filenames,\n",
    "                 test_size=split_ratio_big_dataset,\n",
    "                 random_state=3)\n",
    "\n",
    "print('The full dataset will be comprised of:')\n",
    "print('Train:\\t', len(all_cat_filenames_train), 'cats and', len(all_dog_filenames_train), 'dogs.')\n",
    "print('Val:\\t', len(all_cat_filenames_val), 'cats and', len(all_dog_filenames_val), 'dogs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train and val directories and subdirectories\n",
    "subdirectories = {\"train/cats\": all_cat_filenames_train,\n",
    "                 \"train/dogs\": all_dog_filenames_train,\n",
    "                 \"val/cats\": all_cat_filenames_val,\n",
    "                 \"val/dogs\": all_dog_filenames_val\n",
    "                 }\n",
    "\n",
    "for subdirectory in subdirectories.keys():\n",
    "    subdirectory = Path(subdirectory)\n",
    "    subdirectory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Put the training and validation data in the respective folders\n",
    "def fill_sub_dir(sub_dir, file_subset):\n",
    "    for file in file_subset:\n",
    "        symbolic_path = Path.cwd() / sub_dir / file.name\n",
    "        symbolic_path.symlink_to(file)\n",
    "        \n",
    "for sub_dir, file_subset in subdirectories.items():\n",
    "    fill_sub_dir(sub_dir, file_subset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
