{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checklist for submission\n",
    "\n",
    "It is extremely important to make sure that:\n",
    "\n",
    "1. Everything runs as expected (no bugs when running cells);\n",
    "2. The output from each cell corresponds to its code (don't change any cell's contents without rerunning it afterwards);\n",
    "3. All outputs are present (don't delete any of the outputs);\n",
    "4. Fill in all the places that say `# YOUR CODE HERE`, or \"**Your answer:** (fill in here)\".\n",
    "5. Never copy/paste any notebook cells. Inserting new cells is allowed, but it should not be necessary.\n",
    "6. The notebook contains some hidden metadata which is important during our grading process. **Make sure not to corrupt any of this metadata!** The metadata may for example be corrupted if you copy/paste any notebook cells, or if you perform an unsuccessful git merge / git pull. It may also be pruned completely if using Google Colab, so watch out for this. Searching for \"nbgrader\" when opening the notebook in a text editor should take you to the important metadata entries.\n",
    "7. Although we will try our very best to avoid this, it may happen that bugs are found after an assignment is released, and that we will push an updated version of the assignment to GitHub. If this happens, it is important that you update to the new version, while making sure the notebook metadata is properly updated as well. The safest way to make sure nothing gets messed up is to start from scratch on a clean updated version of the notebook, copy/pasting your code from the cells of the previous version into the cells of the new version.\n",
    "8. If you need to have multiple parallel versions of this notebook, make sure not to move them to another directory.\n",
    "9. Although not forced to work exclusively in the course Docker environment, you need to make sure that the notebook will run in that environment, i.e. that you have not added any additional dependencies.\n",
    "\n",
    "Failing to meet any of these requirements might lead to either a subtraction of POEs (at best) or a request for resubmission (at worst).\n",
    "\n",
    "We advise you the following steps before submission for ensuring that requirements 1, 2, and 3 are always met: **Restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). This might require a bit of time, so plan ahead for this (and possibly use Google Cloud's GPU in HA1 and HA2 for this step). Finally press the \"Save and Checkout\" button before handing in, to make sure that all your changes are saved to this .ipynb file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version_tuple\n",
    "assert python_version_tuple()[:2] == ('3','7'), \"You are not running Python 3.7. Make sure to run Python through the course Docker environment, or alternatively in the provided Conda environment.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that notebook server has access to all required resources, and that notebook has not moved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "nb_dirname = os.path.abspath('')\n",
    "assert nb_dirname != '/notebooks', \\\n",
    "    '[ERROR] The notebook server appears to have been started at the same directory as the assignment. Make sure to start it at least one level above.'\n",
    "assignment_name = os.path.basename(nb_dirname)\n",
    "assert assignment_name in ['IHA1', 'IHA2', 'HA1', 'HA2', 'HA3'], \\\n",
    "    '[ERROR] The notebook appears to have been moved from its original directory'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cells to verify that your notebook is up-to-date and not corrupted in any way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute(`nb_fname = '${IPython.notebook.notebook_name}'`);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from ha_utils import check_notebook_uptodate_and_not_corrupted\n",
    "check_notebook_uptodate_and_not_corrupted(nb_dirname, nb_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in group number and member names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP = \"\"\n",
    "NAME1 = \"\"\n",
    "NAME2 = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "201f5ef89e0a5f1d489ddda4e6746469",
     "grade": false,
     "grade_id": "cell-ce4f9ca6e88f7e01",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# IHA1 - Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "665c7fa5426470e38133071aa6166248",
     "grade": false,
     "grade_id": "cell-d1040a6bdfed8ae8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Welcome to the first individual home assignment!  \n",
    "\n",
    "This assignment consists of two parts:\n",
    " * Python and NumPy exercises\n",
    " * Build a deep neural network for forward propagation\n",
    "  \n",
    "The focus of this assignment is for you to gain practical knowledge with implementing forward propagation of deep neural networks without using any deep learning framework. You will also gain practical knowledge in two of Python's scientific libraries [NumPy](https://docs.scipy.org/doc/numpy-1.13.0/index.html) and [Matplotlib](https://matplotlib.org/devdocs/index.html).  \n",
    "\n",
    "Skeleton code is provided for most tasks and every part you are expected to implement is marked with **TODO**\n",
    "\n",
    "We expect you to search and learn by yourself any commands you think are useful for these tasks. Don't limit yourself to only what was taught in CL1. Use the help function, [stackoverflow](https://stackoverflow.com/), google, the [python documentation](https://docs.python.org/3.5/library/index.html) and the [NumPy](https://docs.scipy.org/doc/numpy-1.13.0/index.html) documentation to your advantage.  \n",
    "\n",
    "**IMPORTANT NOTE**: The tests available are not exhaustive, meaning that if you pass a test you have avoided the most common mistakes, but it is still not guaranteed that you solution is 100% correct.  \n",
    "\n",
    "Lets start by importing the necessary libraries below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e7ac2535fe942aa22cb074b96196da2",
     "grade": false,
     "grade_id": "cell-d2142353d71db431",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.tests.iha1Tests import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "119e1babc3a0b98129291a81e7bf15bd",
     "grade": false,
     "grade_id": "cell-03788efc69dbb922",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Lists and arrays introduction\n",
    "First, we will warm up with a Python exercise and few NumPy exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ebb3ab2ac0813e4d63ddca57223b25e9",
     "grade": false,
     "grade_id": "cell-1eac31835165945d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1 List comprehensions\n",
    "Examine the code snippet provided below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55edad564377f181a1e463011fccc857",
     "grade": false,
     "grade_id": "cell-ee10027e05eff006",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "myList = []\n",
    "for i in range(25):\n",
    "    if i % 2 == 0:\n",
    "        myList.append(i**2)\n",
    "        \n",
    "print(myList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "708ffda8b152deae5f5315135a5a1d49",
     "grade": false,
     "grade_id": "cell-04b896a3a8d65d13",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is not a very \"[pythonic](http://docs.python-guide.org/en/latest/writing/style/)\" way of writing. Lets re-write the code above using a [list comprehension](https://docs.python.org/2/tutorial/datastructures.html#list-comprehensions). The result will be less code, more readable and elegant. Your solution should be able to fit into one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "673d26ff6cb01fe911b4622108157529",
     "grade": true,
     "grade_id": "cell-0fbb6ce83e4dcc85",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "myList = None # TODO\n",
    "# YOUR CODE HERE\n",
    "print(myList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77bfd6f76f3c980654a4fc90d5abf864",
     "grade": false,
     "grade_id": "cell-4de706ba0e5b4060",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sample output from cell above for reference\n",
    "[0, 4, 16, 36, 64, 100, 144, 196, 256, 324, 400, 484, 576]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1efe10702aac297783471227331f4fb0",
     "grade": false,
     "grade_id": "cell-b835734f0fb8c19c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 Numpy array vs numpy vectors\n",
    "Run the cell below to create a numpy array.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23087ad49b6fc8ec3953f819600c59db",
     "grade": false,
     "grade_id": "cell-c391074193d1e66a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "myArr = np.array([1, 9, 25, 49, 81, 121, 169, 225, 289, 361, 441, 529])\n",
    "print(myArr)\n",
    "print(myArr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c6f0caf9dd46bdeb3170490dc0a895d",
     "grade": false,
     "grade_id": "cell-f62ee4516453d169",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "One of the core features of numpy is to efficiently perform linear algebra operations.\n",
    "There are two types of one-dimensional representations in numpy: arrays of shape (x,) and vectors of shape (x,1)\n",
    "\n",
    "The the above result indicates that **myArr** is an array of 12 elements with shape (12,).  \n",
    "\n",
    "Numpy's arrays and vectors both have the type of `numpy.ndarray` but have in some cases different characteristics and it is important to separate the two types because it will save a lot of debugging time later on. Read more about numpy shapes [here](https://stackoverflow.com/a/22074424)   \n",
    "\n",
    "Run the code below to see how the transpose operation behaves differently between an array and vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d29507a6e3afed7cba54b18975dc8c63",
     "grade": false,
     "grade_id": "cell-9ac01dc98f2aad70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# print the shape of an array and the shape of a transposed array\n",
    "print('myArr is an array of shape:')\n",
    "print(myArr.shape)\n",
    "print('The transpose of myArr has the shape:')\n",
    "print(myArr.T.shape)\n",
    "\n",
    "# print the shape of a vector and the transpose of a vector\n",
    "myVec = myArr.reshape(12,1)\n",
    "print('myVec is a vector of shape:')\n",
    "print(myVec.shape)\n",
    "print('The transpose of myVec has the shape:')\n",
    "print(myVec.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40feae83809e5900ed60fe49ef641596",
     "grade": false,
     "grade_id": "cell-954329c6d8a76b67",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3 Numpy exercises\n",
    "Now run the cell below to create the numpy array `numbers` and then complete the exercises sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a974d6601c83b8d357b9d7f734512773",
     "grade": false,
     "grade_id": "cell-b38cd50257c86b2a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "numbers = np.arange(24)\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1982a50a5e13cd7bfc31b87b3a03b633",
     "grade": true,
     "grade_id": "cell-6a9944613f288397",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: reshape numbers into a 6x4 matrix\n",
    "\n",
    "# YOUR CODE HERE\n",
    "print(numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "711da32ec00d4c5c070f743e804f04b9",
     "grade": false,
     "grade_id": "cell-2881aa11ff8233be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sample output from cell above for reference\n",
    "[[ 0  1  2  3]\n",
    " [ 4  5  6  7]\n",
    " [ 8  9 10 11]\n",
    " [12 13 14 15]\n",
    " [16 17 18 19]\n",
    " [20 21 22 23]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "468446fff0845eca34c8359c8bf2394a",
     "grade": false,
     "grade_id": "cell-0a93610d4c83f310",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_numpy_reshape(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53d2335931d7f444df85d01b368639ae",
     "grade": true,
     "grade_id": "cell-eff4d59094285e57",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: set the element of the last row of the last column to zero\n",
    "# Hint: Try what happends when indices are negative\n",
    "\n",
    "# YOUR CODE HERE\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e1e441f5f56e409156fe960ed7f51c3",
     "grade": false,
     "grade_id": "cell-5bd373983cf1ff38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sample output from cell above for reference\n",
    "[[ 0  1  2  3]\n",
    " [ 4  5  6  7]\n",
    " [ 8  9 10 11]\n",
    " [12 13 14 15]\n",
    " [16 17 18 19]\n",
    " [20 21 22  0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4720728a492f976e378f355290f011d1",
     "grade": false,
     "grade_id": "cell-79d591ee24172650",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_numpy_neg_ix(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fbe498b64dc80061d3a30fa816439742",
     "grade": true,
     "grade_id": "cell-3fa4e8328ca5052c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: set every element of the 0th row to 0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05d8efc47cde9c0942a54560b81a2057",
     "grade": false,
     "grade_id": "cell-9bfa316982252d14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sample output from cell above for reference\n",
    "[[ 0  0  0  0]\n",
    " [ 4  5  6  7]\n",
    " [ 8  9 10 11]\n",
    " [12 13 14 15]\n",
    " [16 17 18 19]\n",
    " [20 21 22  0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23028e59b0e1ec213b16ac5482afbbad",
     "grade": false,
     "grade_id": "cell-1cd7674f74a06f63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_numpy_row_ix(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "824ddc90f427a9949c72c849d5cc408e",
     "grade": true,
     "grade_id": "cell-b033e238bf56428b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: append a 1x4 row vector of zeros to `numbers`, \n",
    "# resulting in a 7x4 matrix where the new row of zeros is the last row\n",
    "# Hint: A new matrix must be created in the procedure. Numpy arrays are not dynamic.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "print(numbers)\n",
    "print(numbers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a8b19d318fce9cd2551eb0590238486",
     "grade": false,
     "grade_id": "cell-e7983d6d89cc8816",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sample output from cell above for reference\n",
    "[[ 0  0  0  0]\n",
    " [ 4  5  6  7]\n",
    " [ 8  9 10 11]\n",
    " [12 13 14 15]\n",
    " [16 17 18 19]\n",
    " [20 21 22  0]\n",
    " [ 0  0  0  0]]\n",
    "(7, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c6a4da55dfb09b392063b1e2e0693fe",
     "grade": false,
     "grade_id": "cell-4ce148f238ae1450",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_numpy_append_row(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10ba504de75508432079caec8de423ca",
     "grade": true,
     "grade_id": "cell-e89d22af1e3a0609",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: set all elements above 10 to the value 1\n",
    "\n",
    "# YOUR CODE HERE\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d03420c40671782c8ecc3022144c499",
     "grade": false,
     "grade_id": "cell-f20e202dade5178c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sample output from cell above for reference\n",
    "[[ 0  0  0  0]\n",
    " [ 4  5  6  7]\n",
    " [ 8  9 10  1]\n",
    " [ 1  1  1  1]\n",
    " [ 1  1  1  1]\n",
    " [ 1  1  1  0]\n",
    " [ 0  0  0  0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "070fbac37184cb5fa7543e04d72cdc8c",
     "grade": false,
     "grade_id": "cell-bd6f406141034baa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_numpy_bool_matrix(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec23089bd1ed1325c3d44d0ca87aab0f",
     "grade": true,
     "grade_id": "cell-4d0375ccc2a7ba35",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: compute the sum of every row and replace `numbers` with the answer\n",
    "# `numbers` will be a (7,) array as a result\n",
    "\n",
    "# YOUR CODE HERE\n",
    "print(numbers.shape)\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed06db5c02e3b259ad348f28327814a9",
     "grade": false,
     "grade_id": "cell-87e014a2329b54bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sample output from cell above for reference\n",
    "(7,)\n",
    "[ 0 22 28  4  4  3  0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4784511c0c7cf061c5081f7474697855",
     "grade": false,
     "grade_id": "cell-81c52091be0324bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_numpy_sum(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7cd076557b6e4e20c4623bcebdb86685",
     "grade": false,
     "grade_id": "cell-4889b44b41ac2f64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2 Building your deep neural network\n",
    "It is time to start implementing your first feed-forward neural network. In this lab you will only focus on implementing the forward propagation procedure.  \n",
    "\n",
    "When using a neural network, you can not forward propagate the entire dataset at once. Therefore, you divide the dataset into a number of sets/parts called batches. A batch will make up for the first dimension of every input to a layer and the notation `(BATCH_SIZE, NUM_FEATURES)` simply means the dimension of a batch of samples where every sample has `NUM_FEATURES` features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2fab7ff1f7a904927ae7098581ba80d8",
     "grade": false,
     "grade_id": "cell-d158ea9913a8f3ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1 activation functions\n",
    "You will start by defining a few activation functions that are later needed by the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "70adcd9c1dce54471fa517620a567977",
     "grade": false,
     "grade_id": "cell-6db63ca75af8bb1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2.1.1 ReLU\n",
    "The neural network will use the ReLU activation function in every layer except for the last. ReLU does element-wise comparison of the input matrix. For example, if the input is `X`, and `X[i,j] == 2` and `X[k,l] == -1`, then after applying ReLU, `X[i,j] == 2` and `X[k,l] == 0` should be true.  \n",
    "\n",
    "The formula for implementing ReLU for a single neuron $i$ is:\n",
    "\\begin{equation}\n",
    "relu(z_i) = \n",
    "    \\begin{cases}\n",
    "      0, & \\text{if}\\ z_i \\leq 0 \\\\\n",
    "      z_i, & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "Now implement `relu` in vectorized form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fea5c1a07aa8c504c2a73f591271404a",
     "grade": true,
     "grade_id": "cell-b79ea59bf8e21ff8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    \"\"\" Implement the ReLU activation function\n",
    "    \n",
    "    Arguments:\n",
    "    z - the input of the activation function. Has a type of `numpy.ndarray`\n",
    "    \n",
    "    Returns:\n",
    "    a - the output of the activation function. Has a type of numpy.ndarray and the same shape as `z`\n",
    "    \"\"\"\n",
    "    \n",
    "    a = None # TODO\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a8fbc551f079005eb9dc4589e56c0d8",
     "grade": false,
     "grade_id": "cell-d730211cfe40ec7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_relu(relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20e47ede2cf75fa9940594bbd718f5c3",
     "grade": false,
     "grade_id": "cell-27c5b9a455464663",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2.1.2 Sigmoid\n",
    "The sigmoid activation function is common for binary classification. This is because it squashes its input to the range [0,1].  \n",
    "Implement the activation function `sigmoid` using the formula:  \n",
    "\\begin{equation}\n",
    "    \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0171cc3ff5ebf5cf7d2f4a0770c29d6d",
     "grade": true,
     "grade_id": "cell-9e9398378bf16401",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\" Implement the sigmoid activation function\n",
    "    \n",
    "    Arguments:\n",
    "    z - the input of the activation function. Has a type of `numpy.ndarray`\n",
    "    \n",
    "    Returns:\n",
    "    a - the output of the activation function. Has a type of `numpy.ndarray` and the same shape as `z`\n",
    "    \"\"\"\n",
    "    \n",
    "    a = None # TODO\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f805fd0ccd490b8ddc7735c6caca832",
     "grade": false,
     "grade_id": "cell-80e4f0859983717b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_sigmoid(sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "611434668a6a9f5a377cbc02ba9145ab",
     "grade": false,
     "grade_id": "cell-bb5a658d5e1e8084",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2.1.3 Visualization\n",
    "Make a plot using matplotlib to visualize the activation functions between the input interval [-3,3]. The plot should have the following properties\n",
    " * one plot should contain a visualization of both `ReLU` and `sigmoid`\n",
    " * x-axis: range of values between [-3,3], **hint**: np.linspace\n",
    " * y-axis: the value of the activation functions at a given input `x`\n",
    " * a legend explaining which line represents which activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "585627420ebd3cf90bd69fc292728a9a",
     "grade": true,
     "grade_id": "cell-da02de0b7adca375",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: make a plot of ReLU and sigmoid values in the interval [-3,3]\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17b8fdbad727f3c67be450d007c102ff",
     "grade": false,
     "grade_id": "cell-43aeba42e164e39d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2.1.4 Softmax\n",
    "You will use the softmax activation function / classifier as the final layer of your neural network later in the assignment. Implement `softmax` according the the formula below. The subtraction of the maximum value is there solely to avoid overflows in a practical implementation.\n",
    "\\begin{equation}\n",
    "softmax(z_i) = \\frac{e^{z_i - max(\\mathbf{z})}}{ \\sum^j e^{z_j - max(\\mathbf{z})}}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1df70aa78236c3287266e7788967b76a",
     "grade": true,
     "grade_id": "cell-5394f9e490e15516",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    \"\"\" Implement the softmax activation function\n",
    "    \n",
    "    Arguments:\n",
    "    z - the input of the activation function, shape (BATCH_SIZE, FEATURES) and type `numpy.ndarray`\n",
    "    \n",
    "    Returns:\n",
    "    a - the output of the activation function, shape (BATCH_SIZE, FEATURES) and type umpy.ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "    a = None # TODO\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cabfbb3d29ece42e18832eea66be6e01",
     "grade": false,
     "grade_id": "cell-b2d6814311545a3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_softmax(softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f90d35c5ff5248249b0ec8e4535892bd",
     "grade": false,
     "grade_id": "cell-c6a18169c3533571",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.2 Initialize weights\n",
    "You will implement a helper function that takes the shape of a layer as input, and returns an initialized weight matrix $\\mathbf{W}$ and bias vector $\\mathbf{b}$ as output. $\\mathbf{W}$ should be sampled from a normal distribution of mean 0 and standard deviation 2, and $\\mathbf{b}$ should be initialized to all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1fab6484889665af578a3531ad0e3620",
     "grade": true,
     "grade_id": "cell-b1470eabcc0f1037",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def initialize_weights(layer_shape):\n",
    "    \"\"\" Implement initialization of the weight matrix and biases\n",
    "    \n",
    "    Arguments:\n",
    "    layer_shape - a tuple of length 2, type (int, int), that determines the dimensions of the weight matrix: (input_dim, output_dim)\n",
    "    \n",
    "    Returns:\n",
    "    w - a weight matrix with dimensions of `layer_shape`, (input_dim, output_dim), that is normally distributed with\n",
    "        properties mu = 0, stddev = 2. Has a type of `numpy.ndarray`\n",
    "    b - a vector of initialized biases with shape (1,output_dim), all of value zero. Has a type of `numpy.ndarray`\n",
    "    \"\"\"\n",
    "    w = None # TODO\n",
    "    b = None # TODO\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "928d61e1f4c176c13156294032dafd08",
     "grade": false,
     "grade_id": "cell-1bb5b6ba5c301bbb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_initialize_weights(initialize_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f0ee28df33eee93adeff0fd4a1d4c85",
     "grade": false,
     "grade_id": "cell-e81b2c242af5b016",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.3 Feed-forward neural network layer module\n",
    "To build a feed-forward neural network of arbitrary depth you are going to define a neural network layer as a module that can be used to stack upon eachother.  \n",
    "\n",
    "Your task is to complete the `Layer` class by following the descriptions in the comments.  \n",
    "\n",
    "Recall the formula for forward propagation of an arbitrary layer $l$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{a}^{[l]} = g(\\mathbf{z}^{[l]}) = g(\\mathbf{a}^{[l-1]}\\mathbf{w}^{[l]} +\\mathbf{b}^{[l]})\n",
    "\\end{equation}\n",
    "\n",
    "$g$ is the activation function given by `activation_fn`, which can be relu, sigmoid or softmax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db6ee2c722698233279354f7aa423d91",
     "grade": true,
     "grade_id": "cell-6516b39eaca717d3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\" \n",
    "    TODO: Build a class called Layer that satisfies the descriptions of the methods\n",
    "    Make sure to utilize the helper functions you implemented before\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, activation_fn=relu):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        input_dim - the number of inputs of the layer. type int\n",
    "        output_dim - the number of outputs of the layer. type int\n",
    "        activation_fn - a reference to the activation function to use. Should be `relu` as a default\n",
    "                        possible values are the `relu`, `sigmoid` and `softmax` functions you implemented earlier.\n",
    "                        Has the type `function`\n",
    "        \n",
    "        Attributes:\n",
    "        w - the weight matrix of the layer, should be initialized with `initialize_weights`\n",
    "            and has the shape (INPUT_FEATURES, OUTPUT_FEATURES) and type `numpy.ndarray`\n",
    "        b - the bias vector of the layer, should be initialized with `initialize_weights`\n",
    "            and has the shape (1, OUTPUT_FEATURES) and type `numpy.ndarray`\n",
    "        activation_fn - a reference to the activation function to use.\n",
    "                        Has the type `function`\n",
    "        \"\"\"\n",
    "        self.w, self.b = None, None # TODO\n",
    "        self.activation_fn = None # TODO\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        \n",
    "    def forward_prop(self, a_prev):\n",
    "        \"\"\" Implement the forward propagation module of the neural network layer\n",
    "        Should use whatever activation function that `activation_fn` references to\n",
    "        \n",
    "        Arguments:\n",
    "        a_prev - the input to the layer, which may be the data `X`, or the output from the previous layer.\n",
    "            a_prev has the shape of (BATCH_SIZE, INPUT_FEATURES) and the type `numpy.ndarray`\n",
    "        \n",
    "        Returns:\n",
    "        a - the output of the layer when performing forward propagation. Has the type `numpy.ndarray`\n",
    "        \"\"\"\n",
    "        \n",
    "        a = None # TODO\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "207694d29fc3af1e7f3e41be42d20e90",
     "grade": false,
     "grade_id": "cell-28015fd0a0e48d4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case, be sure that you pass the previous activation function tests before running this test\n",
    "test_layer(Layer, relu, sigmoid, softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "33329644260aab52bfa7963ab01d7ff7",
     "grade": false,
     "grade_id": "cell-85f0a612171d7ec1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.4 Logistic regression \n",
    "Binary logistic regression is a classifier where classification is performed by applying the sigmoid activation function to a linear combination of input values. You will now try out your neural network layer by utilizing it as a linear combination of input values and apply the sigmoid activation function to classify a simple problem. \n",
    "\n",
    "The cell below defines a dataset of 5 points of either class `0` or class `1`. Your assignment is to:  \n",
    "1. Create an instance of a `Layer` with sigmoid activation function  \n",
    "2. Manually tune the weights `w` and `b` of your layer\n",
    "\n",
    "You can use `test_logistic` to visually inspect how your classifier is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2593f77cacac9650ae6036099a137ee7",
     "grade": false,
     "grade_id": "cell-706a31fbfd00b00a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to create the dataset\n",
    "X_s = np.array([[1, 2],\n",
    "               [5, 3],\n",
    "               [8, 8],\n",
    "               [7, 5],\n",
    "               [3, 6]])\n",
    "Y_s = np.array([0,0,1,0,1])\n",
    "\n",
    "test_logistic(X_s, Y_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a0da16975c4f8827fa3a5e3894645ee",
     "grade": true,
     "grade_id": "cell-5cbf8c79f9cf3a33",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create an instance of layer\n",
    "l = Layer(2,1,sigmoid)\n",
    "\n",
    "# TODO: manually tune weights\n",
    "l.w = None\n",
    "l.b = None\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# testing your choice of weights with this function\n",
    "test_logistic(X_s,Y_s,l,sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc1d6f3caff756a8a19390e650b2f2b4",
     "grade": false,
     "grade_id": "cell-293888363cb5ee8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.5 Feed-forward neural network\n",
    "Now define the actual neural network class. It is an L-layer neural network, meaning that the number of layers and neurons in each layer is specified as input by the user. Once again, you will only focus on implementing the forward propagation part.\n",
    "\n",
    "Read the descriptions in the comments and complete the todos  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2939816a3b777ec768b0093523eef497",
     "grade": true,
     "grade_id": "cell-fa7d9fb8891b586e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\" \n",
    "    TODO: Implement an L-layer neural network class by utilizing the Layer module defined above \n",
    "    Each layer should use `relu` activation function, except for the output layer, which should use `softmax`\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_n, layer_dims):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        input_n    - the number of inputs to the network. Should be the same as the length of a data sample\n",
    "                     Has type int\n",
    "        layer_dims - a python list or tuple of the number of neurons in each layer. Layer `l` should have a weight matrix  \n",
    "                     with the shape (`layer_dims[l-1]`, `layer_dims[l]`). \n",
    "                     `layer_dims[-1]` is the dimension of the output layer.\n",
    "                     Layer 1 should have the dimensions (`input_n`, `layer_dims[0]`).\n",
    "                     len(layer_dims) is the depth of the neural network\n",
    "        Attributes:\n",
    "        input_n - the number of inputs to the network. Has type int\n",
    "        layers  - a python list of each layer in the network. Each layer should use the `relu` activation function,\n",
    "                  except for the last layer, which should use `softmax`. \n",
    "                  Has type `list` containing layers of type `Layer`\n",
    "        \"\"\"\n",
    "        \n",
    "        self.input_n = None # TODO\n",
    "        self.layers = None # TODO\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "    def forward_prop(self, x):\n",
    "        \"\"\" \n",
    "        Implement the forward propagation procedure through the entire network, from input to output.\n",
    "        You will now connect each layer's forward propagation function into a chain of layer-wise forward propagations.\n",
    "        \n",
    "        Arguments:\n",
    "        x - the input data, which has the shape (BATCH_SIZE, NUM_FEATURES) and type `numpy.ndarray`\n",
    "        \n",
    "        Returns:\n",
    "        a - the output of the last layer after forward propagating through the every layer in `layers`.\n",
    "            Should have the dimension (BATCH_SIZE, layers[-1].w.shape[1]) and type `numpy.ndarray`\n",
    "        \"\"\"\n",
    "        a = None # TODO\n",
    "        # YOUR CODE HERE\n",
    "            \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e62fb6da9b6207a4e580fe40c66612d",
     "grade": false,
     "grade_id": "cell-cff2a46b776b1af0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_neuralnetwork(NeuralNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52d572ec3968ef4ad48b62d4d1c2dec3",
     "grade": false,
     "grade_id": "cell-64d6b43dc22f747c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3 Making predictions with a neural network\n",
    "In practice, its common to load weights to your neural network that has already been trained.  \n",
    "In this section, you will create an instance of your neural network, load trained weights from disk, and perform predictions.\n",
    "\n",
    "### 3.1 Load weights from disk\n",
    "Create an instance of `NeuralNetwork` with input size $28 \\times 28 = 784$, two hidden layers of size 100 and an output layer of size 10. Thereafter, load the weights contained in `./utils/ann_weights.npz` to your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ae486965b482eed07c98459c56d8d4e",
     "grade": true,
     "grade_id": "cell-c856ed9bd5743c0e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ann = None # TODO: create instance of ann\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# load weights\n",
    "weights = np.load('./utils/ann_weights.npz')\n",
    "for l in range(len(ann.layers)):\n",
    "    ann.layers[l].w = weights['w' + str(l)]\n",
    "    ann.layers[l].b = weights['b' + str(l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4c470c3a61fff3f1ac792a47085b4ff",
     "grade": false,
     "grade_id": "cell-b6ec82c191559e0b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.2 Prediction\n",
    "Now, implement the function `predict_and_correct` which does the following:\n",
    "1. Load `./utils/test_data.npz` from disk\n",
    "2. Extract test data `X` and `Y` from file\n",
    "2. Perform for every pair of data:  \n",
    "    a. plot the image `x`  \n",
    "    b. make a prediction using your neural network by forward propagating and picking the most probable class  \n",
    "    c. check wether the prediction is correct (compare with the ground truth number `y`)   \n",
    "    d. print the predicted label and wether it was correct or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "621dea2f1e259287143c65e0632af3f6",
     "grade": true,
     "grade_id": "cell-3c4a57005fa3ae06",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def predict_and_correct(ann):\n",
    "    \"\"\" Load test data from file and predict using your neural network. \n",
    "    Make a prediction for ever data sample and print it along with wether it was a correct prediction or not\n",
    "    \n",
    "    Arguments:\n",
    "    ann - the neural network to use for prediction. Has type `NeuralNetwork`\n",
    "    \n",
    "    Returns: # for test case purposes\n",
    "    A `numpy.ndarray` of predicted classes (integers [0-9]) with shape (11,)\n",
    "    \"\"\"\n",
    "    data = np.load('./utils/test_data.npz')\n",
    "    X, cls = data['X'], data['Y']\n",
    "    \n",
    "    cls_preds = None # TODO: make a predicted number for every image in X\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        plt.imshow(X[i].reshape(28,28), cmap='gray')\n",
    "        plt.show()\n",
    "        correct = cls_preds[i] == cls[i]\n",
    "        print('The prediction was {0}, it was {1}!'.format(cls_preds[i], 'correct' if correct else 'incorrect'))\n",
    "        \n",
    "    return cls_preds\n",
    "        \n",
    "cls_pred = predict_and_correct(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2997b0ab12a40067133c5c8635f0cd27",
     "grade": false,
     "grade_id": "cell-367000fc5ac1c33f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# final test case\n",
    "test_predict_and_correct_answer(cls_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a49e915629a462648817d0ea9d68cb01",
     "grade": false,
     "grade_id": "cell-0de0870e27634efa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Congratulations!\n",
    "You have successfully implemented a neural network from scratch using only NumPy!  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
