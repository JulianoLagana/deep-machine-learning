{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce4f9ca6e88f7e01",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# IHA1 - Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d1040a6bdfed8ae8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Welcome to the first individual home assignment!  \n",
    "\n",
    "This assignment consists of two parts:\n",
    " * Python and NumPy exercises;\n",
    " * Build a deep neural network for forward propagation.\n",
    "  \n",
    "The focus of this assignment is for you to gain practical knowledge with implementing forward propagation of deep neural networks without using any deep learning framework. You will also gain practical knowledge in two of Python's scientific libraries [NumPy](https://docs.scipy.org/doc/numpy-1.13.0/index.html) and [Matplotlib](https://matplotlib.org/devdocs/index.html).  \n",
    "\n",
    "Skeleton code is provided for most tasks and every part you are expected to implement is marked with **TODO**. Throughout the assignment you will also need to submit written answers to some questions. These questions are mainly to make you reflect on some particular topics and your answers will not be graded in detail. \n",
    "\n",
    "We expect you to search and learn by yourself any commands you think are useful for these tasks. Don't limit yourself to what was taught in CL1. Use the help function, [stackoverflow](https://stackoverflow.com/), google, the [python documentation](https://docs.python.org/3.5/library/index.html) and the [NumPy](https://docs.scipy.org/doc/numpy-1.13.0/index.html) documentation to your advantage.  \n",
    "\n",
    "**IMPORTANT NOTE**: The tests available are not exhaustive, meaning that if you pass a test you have avoided the most common mistakes, but it is still not guaranteed that your solution is 100% correct.  \n",
    "\n",
    "Lets start by importing the necessary libraries below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d2142353d71db431",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.tests.iha1Tests import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-03788efc69dbb922",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Lists and arrays introduction\n",
    "First, we will warm up with a Python exercise and few NumPy exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1eac31835165945d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1 List comprehensions\n",
    "Examine the code snippet provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee10027e05eff006",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "myList = []\n",
    "for i in range(25):\n",
    "    if i % 2 == 0:\n",
    "        myList.append(i**2)\n",
    "        \n",
    "print(myList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-04b896a3a8d65d13",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is not a very \"[pythonic](http://docs.python-guide.org/en/latest/writing/style/)\" way of writing. Lets re-write the code above using a [list comprehension](https://docs.python.org/2/tutorial/datastructures.html#list-comprehensions). The result will be less code, more readable and elegant. Your solution should be able to fit into one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0fbb6ce83e4dcc85",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "myList = None # TODO\n",
    "### BEGIN SOLUTION\n",
    "myList = [ i**2 for i in range(25) if i % 2 == 0]\n",
    "### END SOLUTION\n",
    "print(myList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4de706ba0e5b4060",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sample output from cell above for reference\n",
    "# [0, 4, 16, 36, 64, 100, 144, 196, 256, 324, 400, 484, 576]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b835734f0fb8c19c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 Numpy array vs numpy vectors\n",
    "Run the cell below to create a numpy array.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c391074193d1e66a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "myArr = np.array([1, 9, 25, 49, 81, 121, 169, 225, 289, 361, 441, 529])\n",
    "print(myArr)\n",
    "print(myArr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f62ee4516453d169",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "One of the core features of numpy is to efficiently perform linear algebra operations.\n",
    "There are two types of one-dimensional representations in numpy: arrays of shape (x,) and vectors of shape (x,1).\n",
    "\n",
    "The above result indicates that **myArr** is an array of 12 elements with shape (12,).  \n",
    "\n",
    "Numpy's arrays and vectors both have the type of `numpy.ndarray` but have in some cases different characteristics and it is important to separate the two types because it will save a lot of debugging time later on. Read more about numpy shapes [here](https://stackoverflow.com/a/22074424).\n",
    "\n",
    "Run the code below to see how the transpose operation behaves differently between an array and vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9ac01dc98f2aad70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# print the shape of an array and the shape of a transposed array\n",
    "print('myArr is an array of shape:')\n",
    "print(myArr.shape)\n",
    "print('The transpose of myArr has the shape:')\n",
    "print(myArr.T.shape)\n",
    "\n",
    "# print the shape of a vector and the transpose of a vector\n",
    "myVec = myArr.reshape(12,1)\n",
    "print('myVec is a vector of shape:')\n",
    "print(myVec.shape)\n",
    "print('The transpose of myVec has the shape:')\n",
    "print(myVec.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-954329c6d8a76b67",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3 Numpy exercises\n",
    "Now run the cell below to create the numpy array `numbers` and then complete the exercises sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b38cd50257c86b2a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "numbers = np.arange(24)\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6a9944613f288397",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: reshape numbers into a 6x4 matrix\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "numbers = numbers.reshape(6,4)\n",
    "### END SOLUTION\n",
    "print(numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2881aa11ff8233be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample output from cell above for reference\n",
    "#  [[ 0  1  2  3]\n",
    "#   [ 4  5  6  7]\n",
    "#   [ 8  9 10 11]\n",
    "#   [12 13 14 15]\n",
    "#   [16 17 18 19]\n",
    "#   [20 21 22 23]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0a93610d4c83f310",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_numpy_reshape(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-eff4d59094285e57",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: set the element of the last row of the last column to zero\n",
    "# Hint: Try what happends when indices are negative\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "numbers[-1,-1] = 0\n",
    "### END SOLUTION\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5bd373983cf1ff38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sample output from cell above for reference\n",
    "#  [[ 0  1  2  3]\n",
    "#   [ 4  5  6  7]\n",
    "#   [ 8  9 10 11]\n",
    "#   [12 13 14 15]\n",
    "#   [16 17 18 19]\n",
    "#   [20 21 22  0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-79d591ee24172650",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_numpy_neg_ix(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3fa4e8328ca5052c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: set every element of the 0th row to 0\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "numbers[0,:] = 0\n",
    "### END SOLUTION\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9bfa316982252d14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sample output from cell above for reference\n",
    "#  [[ 0  0  0  0]\n",
    "#   [ 4  5  6  7]\n",
    "#   [ 8  9 10 11]\n",
    "#   [12 13 14 15]\n",
    "#   [16 17 18 19]\n",
    "#   [20 21 22  0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1cd7674f74a06f63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_numpy_row_ix(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b033e238bf56428b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: append a 1x4 row vector of zeros to `numbers`, \n",
    "# resulting in a 7x4 matrix where the new row of zeros is the last row\n",
    "# Hint: A new matrix must be created in the procedure. Numpy arrays are not dynamic.\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "firstRow = np.array([0, 0, 0, 0]).reshape(1,-1) # row vector\n",
    "numbers = np.vstack((numbers,firstRow))\n",
    "### END SOLUTION\n",
    "print(numbers)\n",
    "print(numbers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e7983d6d89cc8816",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sample output from cell above for reference\n",
    "#   [[ 0  0  0  0]\n",
    "#    [ 4  5  6  7]\n",
    "#    [ 8  9 10 11]\n",
    "#    [12 13 14 15]\n",
    "#    [16 17 18 19]\n",
    "#    [20 21 22  0]\n",
    "#    [ 0  0  0  0]]\n",
    "#  (7, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4ce148f238ae1450",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_numpy_append_row(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e89d22af1e3a0609",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: set all elements above 10 to the value 1\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "numbers[numbers > 10] = 1\n",
    "### END SOLUTION\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f20e202dade5178c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sample output from cell above for reference\n",
    "#  [[ 0  0  0  0]\n",
    "#   [ 4  5  6  7]\n",
    "#   [ 8  9 10  1]\n",
    "#   [ 1  1  1  1]\n",
    "#   [ 1  1  1  1]\n",
    "#   [ 1  1  1  0]\n",
    "#   [ 0  0  0  0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bd6f406141034baa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_numpy_bool_matrix(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4d0375ccc2a7ba35",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: compute the sum of every row and replace `numbers` with the answer\n",
    "# `numbers` will be a (7,) array as a result\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "numbers = np.sum(numbers, axis=1)\n",
    "### END SOLUTION\n",
    "print(numbers.shape)\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-87e014a2329b54bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sample output from cell above for reference\n",
    "#   (7,)\n",
    "#   [ 0 22 28  4  4  3  0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-81c52091be0324bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_numpy_sum(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4889b44b41ac2f64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2 Building your deep neural network\n",
    "It is time to start implementing your first feed-forward neural network. In this lab you will only focus on implementing the forward propagation procedure. \n",
    "\n",
    "As you know, a feed-forward neural network consists of a sequence of layers, where the output from one layer is the input to the following layer. Below you can find an example of a feed-forward neural network with 2 hidden layers (blue) and 1 output layer (red). \n",
    "\n",
    "![title](utils/FFNN.png)\n",
    "\n",
    "**What would be your approach to implement a feed-forward neural network? Please provide a brief and high level explanation on how would you implement the several components of network; for instance, would you use any `python` class or only functions?** We will not grade this answer in detail. The objective with this question is to help you reflect upon how to structure the code. This will hopefully enable you to understand the code below more easily. As long as it is clear from your answer that you have tried to briefly describe the overall structure of the code, we will accept your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-de5b4b9eee08a36d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer:** (fill in here)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d25c24207223b552",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this exercise, you will implement several components of a feed-forward network, such as a layers, activation functions and weight initialization functions, and from those create your own feed-forward neural network implementation. \n",
    "\n",
    "NOTE: When using a neural network, due to memory and computational constraints, you can not forward propagate the entire dataset at once. Therefore, you divide the dataset into a number of sets/parts called batches. A batch will make up for the first dimension of every input to a layer and the notation `(BATCH_SIZE, NUM_FEATURES)` simply means the dimension of a batch of samples where every sample has `NUM_FEATURES` features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d158ea9913a8f3ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1 Activation functions\n",
    "You will start by defining a few activation functions that are later needed by the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6db63ca75af8bb1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2.1.1 ReLU\n",
    "The neural network will use the ReLU activation function in every layer except for the last. ReLU does element-wise comparison of the input matrix. For example, if the input is `X`, and `X[i,j] == 2` and `X[k,l] == -1`, then after applying ReLU, `X[i,j] == 2` and `X[k,l] == 0` should be true.  \n",
    "\n",
    "The formula for implementing ReLU for a single neuron $i$ is:\n",
    "\\begin{equation}\n",
    "relu(z_i) = \n",
    "    \\begin{cases}\n",
    "      0, & \\text{if}\\ z_i \\leq 0 \\\\\n",
    "      z_i, & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "Now implement `relu` in vectorized form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b79ea59bf8e21ff8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    \"\"\" Implement the ReLU activation function\n",
    "    \n",
    "    Arguments:\n",
    "    z - the input of the activation function. Has a type of 'numpy.ndarray'\n",
    "    \n",
    "    Returns:\n",
    "    a - the output of the activation function. Has a type of numpy.ndarray and the same shape as 'z'\n",
    "    \"\"\"\n",
    "    \n",
    "    a = None # TODO\n",
    "    ### BEGIN SOLUTION\n",
    "    a = np.maximum(0,z)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d730211cfe40ec7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_relu(relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c174ef6f7a338c73",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Can you name some of the advantages of the ReLU activation function? (We will not grade this answer in detail.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7a3f9caf74b6ad16",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-27c5b9a455464663",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2.1.2 Sigmoid\n",
    "The sigmoid activation function is common for binary classification. This is because it squashes its input to the range [0,1].  \n",
    "Implement the activation function `sigmoid` using the formula:  \n",
    "\\begin{equation}\n",
    "    \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9e9398378bf16401",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\" Implement the sigmoid activation function\n",
    "    \n",
    "    Arguments:\n",
    "    z - the input of the activation function. Has a type of 'numpy.ndarray'\n",
    "    \n",
    "    Returns:\n",
    "    a - the output of the activation function. Has a type of 'numpy.ndarray' and the same shape as 'z'\n",
    "    \"\"\"\n",
    "    \n",
    "    a = None # TODO\n",
    "    ### BEGIN SOLUTION\n",
    "    a = 1 / (1 + np.exp(-z))\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-80e4f0859983717b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_sigmoid(sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-596617a0e1234690",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Why is the sigmoid activation function useful for binary classification? Feel free to use some numerical examples to show how the magnitudes of the variable $z$ affect the output of the sigmoid layer. (We will not grade this answer in detail.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-118c7c24f48006f8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bb5a658d5e1e8084",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2.1.3 Visualization\n",
    "Make a plot using matplotlib to visualize the activation functions between the input interval [-3,3]. The plot should have the following properties\n",
    " * one plot should contain a visualization of both `ReLU` and `sigmoid`;\n",
    " * x-axis: range of values between [-3,3], **hint**: np.linspace;\n",
    " * y-axis: the value of the activation functions at a given input `x`;\n",
    " * a legend explaining which line represents which activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-da02de0b7adca375",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: make a plot of ReLU and sigmoid values in the interval [-3,3]\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "xs = np.linspace(-3,3,1000)\n",
    "plt.plot(xs, relu(xs), label='relu')\n",
    "plt.plot(xs, sigmoid(xs), label='sigmoid')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-43aeba42e164e39d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2.1.4 Softmax\n",
    "You will use the softmax activation function / classifier as the final layer of your neural network later in the assignment. Implement `softmax` according to the formula below. The subtraction of the maximum value is there solely to avoid overflows in a practical implementation.\n",
    "\\begin{equation}\n",
    "softmax(z_i) = \\frac{e^{z_i - max(\\mathbf{z})}}{ \\sum^j e^{z_j - max(\\mathbf{z})}}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5394f9e490e15516",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    \"\"\" Implement the softmax activation function\n",
    "    \n",
    "    Arguments:\n",
    "    z - the input of the activation function, shape (BATCH_SIZE, FEATURES) and type 'numpy.ndarray'\n",
    "    \n",
    "    Returns:\n",
    "    a - the output of the activation function, shape (BATCH_SIZE, FEATURES) and type 'numpy.ndarray'\n",
    "    \"\"\"\n",
    "    \n",
    "    a = None # TODO\n",
    "    ### BEGIN SOLUTION\n",
    "    a = np.exp(z - np.max(z, axis=1, keepdims=True)) / np.exp(z - np.max(z, axis=1, keepdims=True)).sum(axis=1, keepdims=True)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b2d6814311545a3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_softmax(softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c674a3596595bc0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "What are the main differences between using `sigmoid` and `softmax` for multi-class classification problems? And when the number of classes is 2? (We will not grade this answer in detail.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-935e9bef9d68670b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c6a18169c3533571",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.2 Initialize weights\n",
    "You will implement a helper function that takes the shape of a layer as input, and returns an initialized weight matrix $\\mathbf{W}$ and bias vector $\\mathbf{b}$ as output. The matrix $\\mathbf{W}$ should be sampled from a normal distribution with mean 0 and standard deviation 2, and $\\mathbf{b}$ should be initialized to all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b1470eabcc0f1037",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def initialize_weights(layer_shape):\n",
    "    \"\"\" Implement initialization of the weight matrix and biases\n",
    "    \n",
    "    Arguments:\n",
    "    layer_shape - a tuple of length 2, type (int, int), that determines the dimensions of the weight matrix: (input_dim, output_dim)\n",
    "    \n",
    "    Returns:\n",
    "    w - a weight matrix with dimensions of 'layer_shape', (input_dim, output_dim), that is normally distributed with\n",
    "        properties mu = 0, stddev = 2. Has a type of 'numpy.ndarray'\n",
    "    b - a vector of initialized biases with shape (1,output_dim), all of value zero. Has a type of 'numpy.ndarray'\n",
    "    \"\"\"\n",
    "    w = None # TODO\n",
    "    b = None # TODO\n",
    "    ### BEGIN SOLUTION\n",
    "    w = np.random.randn(*layer_shape) * 2\n",
    "    b = np.zeros((1,layer_shape[1]))\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1bb5b6ba5c301bbb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_initialize_weights(initialize_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e81b2c242af5b016",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.3 Feed-forward neural network layer module\n",
    "To build a feed-forward neural network of arbitrary depth you are going to define a neural network layer as a module that can be used to stack layers upon each other. Your task is to complete the `Layer` class by following the descriptions in the comments. Recall the formula for forward propagation of an arbitrary layer $l$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{a}^{[l]} = g(\\mathbf{z}^{[l]}) = g(\\mathbf{a}^{[l-1]}\\mathbf{w}^{[l]} +\\mathbf{b}^{[l]})\n",
    "\\end{equation}\n",
    "\n",
    "where $g$ is the activation function given by `activation_fn`, which can be relu, sigmoid or softmax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6516b39eaca717d3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\" \n",
    "    TODO: Build a class called Layer that satisfies the descriptions of the methods\n",
    "    Make sure to utilize the helper functions you implemented before\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, activation_fn=relu):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        input_dim - the number of inputs of the layer. type int\n",
    "        output_dim - the number of outputs of the layer. type int\n",
    "        activation_fn - a reference to the activation function to use. Should be 'relu' as a default\n",
    "                        possible values are the 'relu', 'sigmoid' and 'softmax' functions you implemented earlier.\n",
    "                        Has the type 'function'\n",
    "        \n",
    "        Attributes:\n",
    "        w - the weight matrix of the layer, should be initialized with 'initialize_weights'\n",
    "            and has the shape (INPUT_FEATURES, OUTPUT_FEATURES) and type 'numpy.ndarray'\n",
    "        b - the bias vector of the layer, should be initialized with 'initialize_weights'\n",
    "            and has the shape (1, OUTPUT_FEATURES) and type 'numpy.ndarray'\n",
    "        activation_fn - a reference to the activation function to use.\n",
    "                        Has the type 'function'\n",
    "        \"\"\"\n",
    "        self.w, self.b = None, None # TODO\n",
    "        self.activation_fn = None # TODO\n",
    "        ### BEGIN SOLUTION\n",
    "        self.w, self.b = initialize_weights((input_dim, output_dim))\n",
    "        self.activation_fn = activation_fn\n",
    "        ### END SOLUTION\n",
    "        \n",
    "        \n",
    "    def forward_prop(self, a_prev):\n",
    "        \"\"\" Implement the forward propagation module of the neural network layer\n",
    "        Should use whatever activation function that 'activation_fn' references to\n",
    "        \n",
    "        Arguments:\n",
    "        a_prev - the input to the layer, which may be the data 'X', or the output from the previous layer.\n",
    "            a_prev has the shape of (BATCH_SIZE, INPUT_FEATURES) and the type 'numpy.ndarray'\n",
    "        \n",
    "        Returns:\n",
    "        a - the output of the layer when performing forward propagation. Has the type 'numpy.ndarray'\n",
    "        \"\"\"\n",
    "        \n",
    "        a = None # TODO\n",
    "        ### BEGIN SOLUTION\n",
    "        z = np.matmul(a_prev, self.w) + self.b \n",
    "        a = self.activation_fn(z)\n",
    "        ### END SOLUTION\n",
    "        \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-28015fd0a0e48d4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case, be sure that you pass the previous activation function tests before running this test\n",
    "test_layer(Layer, relu, sigmoid, softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fd6d28ee4ddb8d3f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.4 Backward propagation\n",
    "\n",
    "In the previous exercise you only implemented the forward propagation of the layer. However, when training a network, you would also need to implement the backward propagation of the layer in order to be able to update its weights. (You won't need to do this in this assignment since you will not train the network. Instead you will load the network weights, which are obtained from a previously trained network.)\n",
    "\n",
    "Provide a high-level explanation of how you would modify your current implementation of the `Layer` class in order to add the backward propagation. (We will not grade this in detail. It is enough that your answer demonstrates that you have thought about how to perform backprop using these classes.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b9b9a482dad01259",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-85f0a612171d7ec1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.5 Example - Logistic regression \n",
    "Binary logistic regression is a classifier where classification is performed by applying the sigmoid activation function to a linear combination of input values. You will now try out your neural network layer by utilizing it as a linear combination of input values and apply the sigmoid activation function to classify a simple problem. \n",
    "\n",
    "The cell below defines a dataset of 5 points of either class `0` or class `1`. Your assignment is to:  \n",
    "1. Create an instance of a `Layer` with the sigmoid activation function;\n",
    "2. Manually tune the weights `w` and bias `b` of your layer.\n",
    "\n",
    "You can use `test_logistic` to visually inspect how your classifier is performing. In order to  be successful in this exercise you need select values for the weights `w` and bias `b` such that all points are classified correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-706a31fbfd00b00a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to create the dataset\n",
    "X_s = np.array([[1, 2],\n",
    "               [5, 3],\n",
    "               [8, 8],\n",
    "               [7, 5],\n",
    "               [3, 6]])\n",
    "Y_s = np.array([0,0,1,0,1])\n",
    "\n",
    "test_logistic(X_s, Y_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5cbf8c79f9cf3a33",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create an instance of layer\n",
    "l = Layer(2,1,sigmoid)\n",
    "\n",
    "# TODO: manually tune weights\n",
    "l.w = None\n",
    "l.b = None\n",
    "### BEGIN SOLUTION\n",
    "l.w = np.array([-1,1.9])\n",
    "l.b = -4\n",
    "### END SOLUTION\n",
    "\n",
    "# testing your choice of weights with this function\n",
    "test_logistic(X_s,Y_s,l,sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-293888363cb5ee8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.6 Feed-forward neural network\n",
    "You will now define the actual neural network class. It is an L-layer neural network, meaning that the number of layers and neurons in each layer is specified as input by the user. Once again, you will only focus on implementing the forward propagation part.\n",
    "\n",
    "Read the descriptions in the comments and complete the **TODO**s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fa7d9fb8891b586e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\" \n",
    "    TODO: Implement an L-layer neural network class by utilizing the Layer module defined above \n",
    "    Each layer should use 'relu' activation function, except for the output layer, which should use 'softmax'\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_n, layer_dims):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        input_n    - the number of inputs to the network. Should be the same as the length of a data sample\n",
    "                     Has type int\n",
    "        layer_dims - a python list or tuple of the number of neurons in each layer. Layer 'l' should have a weight matrix  \n",
    "                     with the shape ('layer_dims[l-1]', 'layer_dims[l]'). \n",
    "                     'layer_dims[-1]' is the dimension of the output layer.\n",
    "                     Layer 1 should have the dimensions ('input_n', 'layer_dims[0]').\n",
    "                     len(layer_dims) is the depth of the neural network\n",
    "        Attributes:\n",
    "        input_n - the number of inputs to the network. Has type int\n",
    "        layers  - a python list of each layer in the network. Each layer should use the 'relu' activation function,\n",
    "                  except for the last layer, which should use 'softmax'. \n",
    "                  Has type 'list' containing layers of type 'Layer'\n",
    "        \"\"\"\n",
    "        \n",
    "        self.input_n = None # TODO\n",
    "        self.layers = None # TODO\n",
    "        ### BEGIN SOLUTION\n",
    "        self.input_n = input_n\n",
    "        self.layers = []\n",
    "        \n",
    "        dims = [input_n] + layer_dims\n",
    "        \n",
    "        for i in range(1, len(dims)-1):\n",
    "            self.layers.append(Layer(dims[i-1], dims[i], relu))\n",
    "                \n",
    "        self.layers.append(Layer(dims[-2], dims[-1], softmax))\n",
    "        ### END SOLUTION\n",
    "        \n",
    "    def forward_prop(self, x):\n",
    "        \"\"\" \n",
    "        Implement the forward propagation procedure through the entire network, from input to output.\n",
    "        You will now connect each layer's forward propagation function into a chain of layer-wise forward propagations.\n",
    "        \n",
    "        Arguments:\n",
    "        x - the input data, which has the shape (BATCH_SIZE, NUM_FEATURES) and type 'numpy.ndarray'\n",
    "        \n",
    "        Returns:\n",
    "        a - the output of the last layer after forward propagating through the every layer in 'layers'.\n",
    "            Should have the dimension (BATCH_SIZE, layers[-1].w.shape[1]) and type 'numpy.ndarray'\n",
    "        \"\"\"\n",
    "        a = None # TODO\n",
    "        ### BEGIN SOLUTION\n",
    "        a = x\n",
    "        for layer in self.layers:\n",
    "            a_prev = a\n",
    "            a = layer.forward_prop(a_prev)\n",
    "        ### END SOLUTION\n",
    "            \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cff2a46b776b1af0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test case\n",
    "test_neuralnetwork(NeuralNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-64d6b43dc22f747c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3 Making predictions with a neural network\n",
    "In practice, its common to load weights to your neural network that has already been trained.  \n",
    "In this section, you will create an instance of your neural network, load trained weights from disk, and perform predictions.\n",
    "\n",
    "### 3.1 Load weights from disk\n",
    "Create an instance of `NeuralNetwork` with input size $28 \\times 28 = 784$, two hidden layers of size 100 and an output layer of size 10. Thereafter, load the weights contained in `./utils/ann_weights.npz` to your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c856ed9bd5743c0e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ann = None # TODO: create instance of ann\n",
    "### BEGIN SOLUTION\n",
    "ann = NeuralNetwork(28*28,[100,100,10])\n",
    "### END SOLUTION\n",
    "\n",
    "# load weights\n",
    "weights = np.load('./utils/ann_weights.npz')\n",
    "for l in range(len(ann.layers)):\n",
    "    ann.layers[l].w = weights['w' + str(l)]\n",
    "    ann.layers[l].b = weights['b' + str(l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b6ec82c191559e0b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.2 Prediction\n",
    "Now, implement the function `predict_and_correct` which does the following:\n",
    "1. Load `./utils/test_data.npz` from disk;\n",
    "2. Extract test data `X` and `Y` from file;\n",
    "3. Perform for every pair of data:  \n",
    "    a. plot the image `x`; <br> \n",
    "    b. make a prediction using your neural network by forward propagating and picking the most probable class;     \n",
    "    c. check whether the prediction is correct (compare with the ground truth number `y`);    \n",
    "    d. print the predicted label and wether it was correct or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3c4a57005fa3ae06",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def predict_and_correct(ann):\n",
    "    \"\"\" Load test data from file and predict using your neural network. \n",
    "    Make a prediction for ever data sample and print it along with wether it was a correct prediction or not\n",
    "    \n",
    "    Arguments:\n",
    "    ann - the neural network to use for prediction. Has type `NeuralNetwork`\n",
    "    \n",
    "    Returns: # for test case purposes\n",
    "    A `numpy.ndarray` of predicted classes (integers [0-9]) with shape (11,)\n",
    "    \"\"\"\n",
    "    data = np.load('./utils/test_data.npz')\n",
    "    X, cls = data['X'], data['Y']\n",
    "    \n",
    "    cls_preds = None # TODO: make a predicted number for every image in X\n",
    "    ### BEGIN SOLUTION\n",
    "    y_preds = ann.forward_prop(X)\n",
    "    cls_preds = np.argmax(y_preds, axis=1)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        plt.imshow(X[i].reshape(28,28), cmap='gray')\n",
    "        plt.show()\n",
    "        correct = cls_preds[i] == cls[i]\n",
    "        print('The prediction was {0}, it was {1}!'.format(cls_preds[i], 'correct' if correct else 'incorrect'))\n",
    "        \n",
    "    return cls_preds\n",
    "        \n",
    "cls_pred = predict_and_correct(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-367000fc5ac1c33f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# final test case\n",
    "test_predict_and_correct_answer(cls_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0de0870e27634efa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Congratulations!\n",
    "You have successfully implemented a neural network from scratch using only NumPy!  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
